{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate JSONS for an occupation/industry classsification scheme\n",
    "\n",
    "This notebook takes input given by the user on occupation/industry classsification scheme of choice as defined in a XLSX format and generates a JSON file. This file is then used downstream by the tool to output a numeric code and description for an occupation definition entered as user input. <br>\n",
    "This numeric code and description output is the closest match the tool has found to the free text description of an occupation input to the tool by user.<br>\n",
    "Each code cell should be run in order to ensure correct operation.  <br>\n",
    "Note that this assumes all prerequisites are satisfied and setup has been completed following the instructions in the [README.md](README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "from occupationcoder.createdictionaries import build_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the (relative) path to the XLSX file where the classification scheme is defined. Also specify name of the sheet that contains the data in the XLSX file. Note this has to be specified even if \"Sheet1\". The file specified in `file_name` variable is assumed to be kept in the `data\\` subfolder of the repository structure. Also, specify in the `code_col` the column name of the column in the XLSX document that contains all the numeric occupation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/ISCO-08 EN Structure and definitions.xlsx\"\n",
    "sheet_name = 'ISCO-08 EN Struct and defin'\n",
    "code_col = 'ISCO 08 Code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file and loading in the data\n",
    "input_df = build_dict.load_file(filename=file_name,\n",
    "                         sheet_name=sheet_name,\n",
    "                         code_col=code_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classification as defined in the `file_name` / `sheet_name` above will be some text that are redundant and should be removed before the classification is put into a JSON. \n",
    "Currently as defined in the next cell, the column names and the corresponding text to delete relate to the ISCO classification scheme.\n",
    "The names of the columns that contains text to be removed should replace the current column names of 'Tasks include' and 'Included occupations'.  <br>\n",
    "The corresponding text or phrases to be removed from the columns should be listed within the square brackets, separated by a comma and each phrase or text to be within the speech marks.  <br>\n",
    "The values pre-populated below are provided as examples only and should be modified to match the given occupation classification scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_text = {'Tasks include': ['Tasks performed', 'Tasks include', 'Tasks performed by', 'usually include'],\n",
    "                    'Included occupations': ['Examples of the occupations classified here:',\n",
    "                                             'Occupations in this major group are classified into the following',\n",
    "                                             'Occupations in this sub-major group are classified into the following',\n",
    "                                             'Occupations in this minor group are classified into the following',\n",
    "                                             'major group', 'minor group', 'sub-major group', 'sub-', 'unit group'\n",
    "                                             ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the names of the columns containing the following information:\n",
    "\n",
    "- `code_col`, The column name in the XLSX file assigned to `file_name`/ `sheet_name` that contains numeric codes for occupation descriptions in classification scheme.\n",
    "- `bucket_cols`(list): List of strings, corresponding to column names to be processed into word buckets.\n",
    "- `exact_col`, (str, optional): String, corresponding to dataframe column containing expected exact job title matches. The default is ''.\n",
    "- `exact_col_split`, (str, optional): Character string that represents how job title matches in exact_col are to be split. Could for example be hard returns ('\\n') or dashes ('*). Only needed when exact_col is specified.\n",
    "- `exclude_text`, (dict, optional): Dictionary of lists of strings, where keys correspond to columns from which substrings should be removed, and values are lists of substrings to removed from the given column. Only needed if exact_col is specified.\n",
    "- `exclude_pattern`, (str, optional): Regex expression to remove from any given column. \n",
    "- `output_files`, (dict): Dictionary specifying output file names for word bucket JSON and exact match JSON outputs (if needed). Keys should be specified as 'buckets' and 'exact', and values should be strings of output file names. Default: {'buckets': 'buckets.json', 'exact': 'titles.json'}.\n",
    "- `bucket_field_names` (list, optional): List of strings specifying field titles in word bucket JSON. Defaults: ['code','description'].\n",
    "- `level`, (list, optional): List of level codes (numbers) to process. If not specified (default: None), all levels present in input are included.\n",
    "\n",
    "The values pre-populated below are provided as examples only and should be modified to match the given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_dict.process_file(input_df=input_df,\n",
    "                            code_col=code_col,\n",
    "                            bucket_cols=['Title EN', 'Definition', 'Tasks include'],\n",
    "                            exact_col='Included occupations',\n",
    "                            exact_col_split='\\n',\n",
    "                            exclude_text=exclude_text,\n",
    "                            output_files= {'buckets': 'isco/buckets_isco.json', 'exact': 'isco/titles_isco.json'},\n",
    "                            bucket_field_names=['isco_code', 'Titles_nospace'],\n",
    "                            level=4\n",
    "                            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsa_occ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
